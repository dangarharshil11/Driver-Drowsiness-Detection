{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKt3_C_Wm51D"
   },
   "source": [
    "# 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cev5vt-6m51F"
   },
   "outputs": [],
   "source": [
    "!cd '/content/drive/MyDrive/New folder' && pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuXwxqH9m51F"
   },
   "outputs": [],
   "source": [
    "!cd '/content/drive/MyDrive/New folder' && git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_7gBQus5m51G"
   },
   "outputs": [],
   "source": [
    "!cd '/content/drive/MyDrive/New folder/yolov5' & pip3 install -r '/content/drive/MyDrive/New folder/yolov5/requirements.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orFoAWs0m51G"
   },
   "source": [
    "# 2. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ePZX2LKlm51G"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IQwoNF_0m51G"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\danga/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-1-26 Python-3.9.13 torch-1.8.1+cu111 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nqcI69e6m51H"
   },
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vFUO3Nom51H"
   },
   "source": [
    "# 3. Make Detections with Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eo7yIBZm51H"
   },
   "outputs": [],
   "source": [
    "img = 'https://a57.foxnews.com/a57.foxnews.com/static.foxnews.com/foxnews.com/content/uploads/2018/09/640/320/1862/1048/1704f8e8-Massive-Traffic-Highway-Transportation.jpg?ve=1&tl=1?ve=1&tl=1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ny4WP-Irm51H"
   },
   "outputs": [],
   "source": [
    "results = model(img)\n",
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pN4Rhzgm51I"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmk0aDHYm51I"
   },
   "outputs": [],
   "source": [
    "results.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfBNjxjXm51I"
   },
   "source": [
    "# 4. Real Time Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDBblH-9m51I"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Make detections \n",
    "    results = model(frame)\n",
    "    \n",
    "    cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSXI48tkm51J"
   },
   "source": [
    "# 5. Train from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LlVUzaLYm51J"
   },
   "outputs": [],
   "source": [
    "import uuid   # Unique identifier\n",
    "import os\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fXwyDPoem51J"
   },
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('data', 'new_images') #/data/images\n",
    "labels = ['awake', 'drowsy']\n",
    "number_imgs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpVhfQ0Bm51J"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Loop through labels\n",
    "for label in labels:\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Loop through image range\n",
    "    for img_num in range(number_imgs):\n",
    "        print('Collecting images for {}, image number {}'.format(label, img_num))\n",
    "        \n",
    "        # Webcam feed\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Naming out image path\n",
    "        imgname = os.path.join(IMAGES_PATH, label+'.'+str(uuid.uuid1())+'.jpg')\n",
    "        \n",
    "        # Writes out image to file \n",
    "        cv2.imwrite(imgname, frame)\n",
    "        \n",
    "        # Render to the screen\n",
    "        cv2.imshow('Image Collection', frame)\n",
    "        \n",
    "        # 2 second delay between captures\n",
    "        time.sleep(2)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIVAlq2Xm51K"
   },
   "outputs": [],
   "source": [
    "print(os.path.join(IMAGES_PATH, labels[0]+'.'+str(uuid.uuid1())+'.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCWkc-VNm51K"
   },
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    for img_num in range(number_imgs):\n",
    "        print('Collecting images for {}, image number {}'.format(label, img_num))\n",
    "        imgname = os.path.join(IMAGES_PATH, label+'.'+str(uuid.uuid1())+'.jpg')\n",
    "        print(imgname)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrZdq1Wjm51K"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/tzutalin/labelImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bc58I7WSm51K"
   },
   "outputs": [],
   "source": [
    "!pip install pyqt5 lxml --upgrade\n",
    "!pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1o7hwHf0m51L"
   },
   "outputs": [],
   "source": [
    "!python train.py --img 320 --batch 16 --epochs 500 --data dataset.yml --weights yolov5s.pt --workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUdv3sNqm51L"
   },
   "source": [
    "# 6. Load Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "S2pRq3xFm51L"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to C:\\Users\\danga/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2023-1-31 Python-3.9.13 torch-1.8.1+cu111 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7055974 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path= 'yolov5/runs/train/exp8/weights/last.pt', force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wy8GT9fpm51M"
   },
   "outputs": [],
   "source": [
    "img = os.path.join('/content/drive/MyDrive/New folder/data', 'images', 'drowsy.973f53ec-96ef-11ed-b4cd-60a5e28c842a.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cq7vtYb3m51M"
   },
   "outputs": [],
   "source": [
    "results = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzmoBpeRm51M"
   },
   "outputs": [],
   "source": [
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ff6e1YE_m51M"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SAm5MbmOm51M"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Make detections \n",
    "    results = model(frame)\n",
    "    \n",
    "    cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Z0VjNJDOHyUU"
   },
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import requests\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "# Replace the below URL with your own. Make sure to add \"/shot.jpg\" at last.\n",
    "url = \"http://192.0.0.4:8080/shot.jpg\"\n",
    "\n",
    "# While loop to continuously fetching data from the Url\n",
    "while True:\n",
    "    img_resp = requests.get(url)\n",
    "    img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_arr, -1)\n",
    "    img = imutils.resize(img, width=500, height=900)\n",
    "    results = model(img)\n",
    "\n",
    "    cv2.imshow(\"Android_cam\", np.squeeze(results.render()))\n",
    "\n",
    "\t# Press Esc key to exit\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to C:\\Users\\danga/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2023-1-26 Python-3.9.13 torch-1.8.1+cu111 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7055974 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import customtkinter as ctk \n",
    "\n",
    "import torch\n",
    "import Numpy as np\n",
    "\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import random\n",
    "from pygame import mixer\n",
    "\n",
    "mixer.init()\n",
    "sound= mixer.Sound(r'H:\\Study\\6th Sem\\Python Project\\My-Project\\Data set\\sound.mp3')\n",
    "app = tk.Tk()\n",
    "app.geometry(\"600x600\")\n",
    "app.title(\"Drowsy Boi 4.0\")\n",
    "ctk.set_appearance_mode(\"dark\")\n",
    "\n",
    "vidFrame = tk.Frame(height=480, width=600)\n",
    "vidFrame.pack()\n",
    "vid = ctk.CTkLabel(vidFrame)\n",
    "vid.pack()\n",
    "\n",
    "counter = 0 \n",
    "root = tk.Tk()\n",
    "\n",
    "counterLabel = ctk.CTkLabel(root,text=counter,  height=40, width=120, text_color=\"white\", fg_color=\"teal\")\n",
    "counterLabel.pack(pady=10)\n",
    "\n",
    "def reset_counter(): \n",
    "    global counter\n",
    "    counter = 0 \n",
    "resetButton = ctk.CTkButton(root,text=\"Reset Counter\", command=reset_counter, height=40, width=120, text_color=\"white\", fg_color=\"teal\") \n",
    "resetButton.pack()\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5/runs/train/exp8/weights/last.pt', force_reload=True)\n",
    "cap = cv2.VideoCapture(0)\n",
    "def detect(): \n",
    "    global counter\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "    results = model(frame) \n",
    "    img = np.squeeze(results.render())\n",
    "\n",
    "    if len(results.xywh[0]) > 0: \n",
    "        dconf = results.xywh[0][0][4]\n",
    "        dclass = results.xywh[0][0][5]\n",
    "\n",
    "        if dconf.item() > 0.85 and dclass.item() == 1.0:\n",
    "            sound.play() \n",
    "            counter += 1 \n",
    "\n",
    "    imgarr = Image.fromarray(img)\n",
    "    imgtk = ImageTk.PhotoImage(imgarr) \n",
    "    vid.imgtk = imgtk\n",
    "    vid.configure(image=imgtk)\n",
    "    vid.after(10, detect) \n",
    "    counterLabel.configure(text=counter)  \n",
    "\n",
    "\n",
    "detect()\n",
    "app.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
